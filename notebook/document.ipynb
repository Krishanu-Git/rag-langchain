{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3df15a29",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7660bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35407f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'example.txt', 'pages': 1, 'author': 'Krishanu Das', 'date_created': '2025-01-01'}, page_content='This is the main text content I am using to create rag')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = Document(\n",
    "    page_content=\"This is the main text content I am using to create rag\",\n",
    "    metadata = {\n",
    "        \"source\":\"example.txt\",\n",
    "        \"pages\": 1,\n",
    "        \"author\": \"Krishanu Das\",\n",
    "        \"date_created\": \"2025-01-01\"\n",
    "    }\n",
    ")\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec4b15dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple text file\n",
    "import os\n",
    "os.makedirs('../data/text_files', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42eb7c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text files created\n"
     ]
    }
   ],
   "source": [
    "sample_texts = {\n",
    "    \"../data/text_files/python_intro.txt\":\"Python is a language that feels like it was designed on a calm Sunday morning. You write a few lines, and suddenly things just… work. Lists stretch and shrink like elastic, dictionaries quietly hold secrets in key-value pairs, and functions politely accept just about anything you hand them. One moment you’re looping through nested data structures like an explorer navigating a digital jungle, and the next you’re importing libraries that turn your tiny script into a data-crunching powerhouse. Whether it's automating a boring task or spinning up a quick API, Python is the friendly companion that never complains about indentation—as long as you respect the tabs and spaces.\",\n",
    "    \"../data/text_files/rag_intro.txt\":\"RAG is like giving an AI a backpack full of books and saying, “Don’t just guess—go look it up.” Instead of hallucinating confidently like it owns the universe, the model pauses, fetches chunks of real information from a vector store, and then crafts an answer that actually makes sense. Embeddings act like the secret GPS coordinates pointing to the most relevant documents, while retrievers quietly drag them back from the depths of your knowledge base. Suddenly, your chatbot knows company policies better than HR and answers tech queries faster than the dev team on caffeine. With RAG, AI becomes less of a storyteller and more of a reliable assistant—still creative, but with receipts.\"\n",
    "}\n",
    "\n",
    "for file_path, text in sample_texts.items():\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "\n",
    "print(\"Sample text files created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a511716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '../data/text_files/python_intro.txt'}, page_content=\"Python is a language that feels like it was designed on a calm Sunday morning. You write a few lines, and suddenly things just… work. Lists stretch and shrink like elastic, dictionaries quietly hold secrets in key-value pairs, and functions politely accept just about anything you hand them. One moment you’re looping through nested data structures like an explorer navigating a digital jungle, and the next you’re importing libraries that turn your tiny script into a data-crunching powerhouse. Whether it's automating a boring task or spinning up a quick API, Python is the friendly companion that never complains about indentation—as long as you respect the tabs and spaces.\")]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text loader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "loader = TextLoader(\"../data/text_files/python_intro.txt\", encoding=\"utf-8\")\n",
    "document = loader.load()\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64a9c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RAG is like giving an AI a backpack full of books and saying, “Don’t just guess—go look it up.” Instead of hallucinating confidently like it owns the universe, the model pauses, fetches chunks of real information from a vector store, and then crafts an answer that actually makes sense. Embeddings act like the secret GPS coordinates pointing to the most relevant documents, while retrievers quietly drag them back from the depths of your knowledge base. Suddenly, your chatbot knows company policies better than HR and answers tech queries faster than the dev team on caffeine. With RAG, AI becomes less of a storyteller and more of a reliable assistant—still creative, but with receipts.',\n",
       " \"Python is a language that feels like it was designed on a calm Sunday morning. You write a few lines, and suddenly things just… work. Lists stretch and shrink like elastic, dictionaries quietly hold secrets in key-value pairs, and functions politely accept just about anything you hand them. One moment you’re looping through nested data structures like an explorer navigating a digital jungle, and the next you’re importing libraries that turn your tiny script into a data-crunching powerhouse. Whether it's automating a boring task or spinning up a quick API, Python is the friendly companion that never complains about indentation—as long as you respect the tabs and spaces.\"]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# directory loader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"../data/text_files\",\n",
    "    glob='**/*.txt',\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\n",
    "        'encoding':'utf-8'\n",
    "    },\n",
    "    show_progress=False\n",
    ")\n",
    "documents = dir_loader.load()\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbf9d23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-07-22T09:44:08+00:00', 'source': '../data/pdf/Assigntment 2.pdf', 'file_path': '../data/pdf/Assigntment 2.pdf', 'total_pages': 3, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-07-22T09:44:08+00:00', 'trapped': '', 'modDate': 'D:20250722094408Z', 'creationDate': 'D:20250722094408Z', 'page': 0}, page_content='Indian Institute of Technology Jodhpur\\nFundamentals of Distributed Systems\\nAssignment – 2\\nTotal Marks:\\n20\\nSubmission Deadline:\\n27 July 2025'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-07-22T09:44:08+00:00', 'source': '../data/pdf/Assigntment 2.pdf', 'file_path': '../data/pdf/Assigntment 2.pdf', 'total_pages': 3, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-07-22T09:44:08+00:00', 'trapped': '', 'modDate': 'D:20250722094408Z', 'creationDate': 'D:20250722094408Z', 'page': 1}, page_content='Datasets\\n• Cruise data: Cruise CSV file (click here to download)\\n• Customer churn data: Customer Churn CSV file (click here to download)\\n• E-commerce customer data: E-commerce Customer CSV file (click here to down-\\nload)\\nInstructions\\n• Implement all MapReduce jobs using the mrjob library and Hadoop in Google Colab.\\n• At the top of your notebook, install dependencies and setup hadoop.\\n• Load each CSV directly from the URLs above using wget or curl command into the\\nGoogle Colab.\\n• For each question:\\n1. Write mapper, reducer (and combiners or multi-step definitions) as mrjob classes.\\n2. Include a brief docstring explaining your design in Google Colab using markdown\\nfeature for each question and cell of Colab.\\n3. Demonstrate correctness on a small inline example.\\n• Name your notebook Assignment2-(Roll No of Yours)-(Name of yours).ipynb\\nand submit a link to GitHub or Colab and also submit the Jupyter notebook file in LMS.\\n• At the end, include a cell that runs all jobs on full datasets and shows final outputs.\\nQuestions\\n1. Cruiseline Aggregations (5 marks)\\nUsing cruise.csv, implement an mrjob class that computes, for each Cruise line:\\n(a) Total number of ships.\\n(b) Average Tonnage (to two decimals).\\n(c) Maximum crew size.\\n(Optional) Use a Combiner for partial aggregation.\\n2. Company Churn Rate (5 marks)\\nFrom customer churn.csv, create a MultiStepJob:\\nStep 1: Mapper emits (Company, TOTAL) and (Company, CHURNED) where Churn==1.\\nStep 2: Reducer computes churn rate = CHURNED\\nTOTAL , outputting four-decimal floats.\\nUse a small VIP companies.txt in the distributed cache to restrict to listed companies.\\nProvide a sample file with at least three names.\\n1'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-07-22T09:44:08+00:00', 'source': '../data/pdf/Assigntment 2.pdf', 'file_path': '../data/pdf/Assigntment 2.pdf', 'total_pages': 3, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-07-22T09:44:08+00:00', 'trapped': '', 'modDate': 'D:20250722094408Z', 'creationDate': 'D:20250722094408Z', 'page': 2}, page_content='3. State-wise Spending (5 marks)\\nFrom e-com customer.csv, extract the two-letter state code from the Address field.\\nThen:\\n• Mapper parses the state.\\n• Reducer sums Yearly Amount Spent per state.\\n• Output the top 5 states by total spending.\\n4. Two-step Ship Filter & Median Length (5 marks)\\nOn cruise.csv, implement a two-step mrjob pipeline:\\nStep 1: Filter ships with passenger density > 35.0; emit ⟨Cruise line, length⟩.\\nStep 2: Compute the median of the lengths per Cruise line, handling even/odd counts\\ncorrectly.\\nUse the steps() API and output medians to two decimals.\\nSubmission\\n• Submit Assignment2.ipynb with all code, inline tests, proper brief markup comments\\nfor each question and final outputs.\\n• Ensure each question’s results are clearly labeled.\\n• Provide a GitHub or Colab link for assessment.\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-06-13T15:44:27+00:00', 'source': '../data/pdf/Assignment 1.pdf', 'file_path': '../data/pdf/Assignment 1.pdf', 'total_pages': 5, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-06-13T15:44:27+00:00', 'trapped': '', 'modDate': 'D:20250613154427Z', 'creationDate': 'D:20250613154427Z', 'page': 0}, page_content='Indian Institute of Technology Jodhpur\\nFundamentals of Distributed Systems\\nAssignment – 1\\nTotal Marks:\\n20\\nSubmission Deadline:\\n23 June 2025'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-06-13T15:44:27+00:00', 'source': '../data/pdf/Assignment 1.pdf', 'file_path': '../data/pdf/Assignment 1.pdf', 'total_pages': 5, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-06-13T15:44:27+00:00', 'trapped': '', 'modDate': 'D:20250613154427Z', 'creationDate': 'D:20250613154427Z', 'page': 1}, page_content='1. Vector Clocks and Causal Ordering\\n[10 Marks]\\nObjective\\nTo move beyond simple event ordering by implementing Vector Clocks to capture the causal\\nrelationships between events in a distributed system. You will apply this to build a causally\\nconsistent, multi-node key-value store.\\nProblem Description\\nYou will build a distributed key-value store with three or more nodes. The key challenge is\\nto ensure that writes to the store are causally ordered. If event B is causally dependent on\\nevent A (e.g., a value is read and then updated), all nodes must process event A before they\\nprocess event B. Simple Lamport clocks are insufficient for this, so you will use Vector Clocks.\\nTechnology Constraints\\n• Programming Language: The entire application logic for the nodes and client must\\nbe written exclusively in Python.\\n• Containerization: The system must be containerized and orchestrated solely using\\nDocker and Docker Compose.\\nTasks\\nYour implementation should cover the following tasks:\\n1. Node Implementation with Vector Clocks: Create a Python script for a node. Each\\nnode must maintain its own local key-value data and a Vector Clock.\\n2. Vector Clock Logic: Implement the rules for incrementing the clock on local events,\\nincluding the clock in sent messages, and updating the local clock upon receiving a\\nmessage.\\n3. Causal Write Propagation: Implement the Causal Delivery Rule.\\nWhen a node\\nreceives a replicated write message, it must delay processing that write until the causal\\ndependencies are met by checking the message’s vector clock against its own. Messages\\nthat cannot be delivered must be buffered.\\n4. Containerization and Networking: Write a ‘Dockerfile‘ for your node and a ‘docker-\\ncompose.yml‘ file to run a 3-node system.\\n5. Verification and Scenario Testing: Create a client script and a specific test scenario\\nto prove that your system maintains causal consistency, even when messages arrive out\\nof order.\\n1'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-06-13T15:44:27+00:00', 'source': '../data/pdf/Assignment 1.pdf', 'file_path': '../data/pdf/Assignment 1.pdf', 'total_pages': 5, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-06-13T15:44:27+00:00', 'trapped': '', 'modDate': 'D:20250613154427Z', 'creationDate': 'D:20250613154427Z', 'page': 2}, page_content='Deliverables\\nYour final submission must be a single Git repository containing all the required files organized\\nin the exact structure shown below.\\nFolder and File Structure\\n1 vector -clock -kv -store/\\n2 |\\n3 |-- src/\\n4 |\\n|-- node.py\\n5 |\\n‘-- client.py\\n6 |\\n7 |-- Dockerfile\\n8 |-- docker -compose.yml\\n9 ‘-- project_report .pdf\\nProject Report Requirements\\nYou must submit a thorough Project Report that details your work.\\n• Format: The report must be a typed document (e.g., created in Microsoft Word,\\nGoogle Docs, or LATEX) and submitted as a single ‘project report.pdf‘ file. Handwritten\\nreports will not be accepted.\\n• Content: The report should detail your architecture and implementation and use logs\\nwith screenshots to prove that your causal consistency test works correctly.\\n• Video Link: The report must include a publicly accessible link to a short (max 3-\\nminute) video demonstrating the project.\\n2. Dynamic Load Balancing for a Smart Grid\\n[10 Marks]\\nObjective\\nTo design and build a scalable system for a Smart Grid that dynamically balances Electric\\nVehicle (EV) charging requests across multiple substations based on their real-time load,\\ncomplete with a comprehensive observability stack.\\nProblem Description\\nYou will build a system that simulates a Smart Grid managing charging requests from a\\nfleet of EVs. The primary challenge is to prevent overloading any single charging substation.\\nThe system must intelligently distribute incoming charging requests to the least loaded\\nsubstation, ensuring grid stability and efficient resource usage.\\nYou will use an industry-\\nstandard monitoring stack to measure and visualize key performance indicators.\\n2'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-06-13T15:44:27+00:00', 'source': '../data/pdf/Assignment 1.pdf', 'file_path': '../data/pdf/Assignment 1.pdf', 'total_pages': 5, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-06-13T15:44:27+00:00', 'trapped': '', 'modDate': 'D:20250613154427Z', 'creationDate': 'D:20250613154427Z', 'page': 3}, page_content='Technology Constraints\\n• Programming Language: All custom services must be written exclusively in Python.\\n• Containerization & Orchestration: The entire system must be defined, configured,\\nand run using Docker and Docker Compose.\\nTasks\\nYour implementation should cover the following tasks:\\n1. Microservice Development: Create two services: a ‘charge request service‘ as the\\npublic entry point and a ‘substation service‘ that simulates charging. Instrument the\\nsubstation to expose its current load as a Prometheus metric.\\n2. Custom Dynamic Load Balancer: Build a new service that acts as the grid’s core\\nlogic. It must periodically poll the ‘/metrics‘ endpoint of each substation to get its\\ncurrent load and use this data to decide where to route new requests.\\n3. Observability Stack: Configure Prometheus to scrape the substation metrics and\\nGrafana to visualize the load on a dashboard.\\n4. Containerization & Orchestration: Write ‘Dockerfile‘s for all services and a ‘docker-\\ncompose.yml‘ file to run the entire system, including multiple replicas of the substation\\nservice.\\n5. Load Testing and Analysis: Create a Python script to simulate a ”rush hour” of EV\\ncharging requests and analyze the system’s response on your Grafana dashboard.\\nDeliverables\\nYour final submission must be a single Git repository containing all the required files organized\\nin the exact structure shown below.\\nFolder and File Structure\\n1 smart -grid -load -balancer/\\n2 |\\n3 |-- charge_request_service /\\n4 |\\n|-- main.py\\n5 |\\n‘-- Dockerfile\\n6 |\\n7 |-- load_balancer/\\n8 |\\n|-- main.py\\n9 |\\n‘-- Dockerfile\\n10 |\\n11 |-- substation_service /\\n12 |\\n|-- main.py\\n13 |\\n‘-- Dockerfile\\n14 |\\n15 |-- load_tester/\\n16 |\\n‘-- test.py\\n17 |\\n18 |-- monitoring/\\n3'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.26', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-06-13T15:44:27+00:00', 'source': '../data/pdf/Assignment 1.pdf', 'file_path': '../data/pdf/Assignment 1.pdf', 'total_pages': 5, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-06-13T15:44:27+00:00', 'trapped': '', 'modDate': 'D:20250613154427Z', 'creationDate': 'D:20250613154427Z', 'page': 4}, page_content='19 |\\n|-- prometheus/\\n20 |\\n|\\n‘-- prometheus.yml\\n21 |\\n‘-- grafana/\\n22 |\\n‘-- dashboard.json\\n23 |\\n24 |-- docker -compose.yml\\n25 ‘-- project_report .pdf\\nProject Report Requirements\\nYou must submit a thorough Project Report that details your work.\\n• Format: The report must be a typed document and submitted as a single project report.pdf\\nfile. Handwritten reports will not be accepted.\\n• Content: The report should detail your architecture and analyze the system’s perfor-\\nmance using screenshots from your Grafana dashboard during the load test.\\n• Video Link: The report must include a publicly accessible link to a short (max 3-\\nminute) video demonstrating the project in action.\\n4'),\n",
       " Document(metadata={'producer': 'pdfTeX-1.40.24', 'creator': 'TeX', 'creationdate': '2025-04-12T18:02:53+05:30', 'source': '../data/pdf/assignment.pdf', 'file_path': '../data/pdf/assignment.pdf', 'total_pages': 1, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-04-12T18:02:53+05:30', 'trapped': '', 'modDate': \"D:20250412180253+05'30'\", 'creationDate': \"D:20250412180253+05'30'\", 'page': 0}, page_content='Assignment\\n1. A drawer contains two coins. One is an unbiased coin, which when tossed, is equally likely to turn up heads or\\ntails. The other is a biased coin, which will turn up heads with probability p and tails with probability 1 −p.\\nOne coin is selected (uniformly) at random from the drawer. Two experiments are performed:\\n(i) The selected coin is tossed n times. Given that the coin turns up heads k times and tails n−k times, what\\nis the probability that the coin is biased?\\n(ii) The selected coin is toss repeatedly until it turns up heads k times. Given that the coin is tossed n times in\\ntotal, what is the probability that the coin is biased?\\n2. Which of the following functions are probability density functions:\\n(i) f(x) = x(2−x), 0 < x < 2, and 0 elsewhere.\\n(ii) f(x) = 1\\nλ e−(x−θ)/λ, x > θ, and 0 elsewhere, λ > 0.\\n(iii) f(x) = sinx, 0 < x < π/2, and 0 elsewhere.\\n3. A workstation consists of three machines, M1, M2 and M3, each of which will fail after an amount of time Ti\\nwhich is an independent exponentially distributed random variable, with parameter 1. Assume that the times to\\nfailure of the different machines are independent. The workstation fails as soon as both of the following have\\nhappened:\\n(i) Machine M1 has failed.\\n(ii) Atleast one of the machines M2 or M3 has failed.\\nFind the expected value of the time to failure of the workstation.\\n4. A and B throw alternatively with a pair of balanced dice. A wins if he throws a sum of 6 points before B throws\\na sum of 7 points, while B wins if he throws a sum of 7 points before A throws a sum of 6 points. Suppose that\\nA begins the game. What is the probability that A will win the game?\\n5. A post office has 2 clerks. Nikita enters the post office while 2 other customers, Rohan and Ankita, are being\\nserved by the 2 clerks. She is next in line. Assume that the time a clerk spends serving a customer has the\\nExponential(λ) distribution.\\n(a) What is the probability that Nikita is the last of the 3 customers to be done being served?\\n(b) What is the expected total time that Nikita needs to spend at the post office?')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader, DirectoryLoader\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"../data/pdf\",\n",
    "    glob=\"**/*.pdf\",\n",
    "    loader_cls=PyMuPDFLoader,\n",
    "    show_progress=False\n",
    ")\n",
    "documents = dir_loader.load()\n",
    "documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
